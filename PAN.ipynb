{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPiQrtEzs/km4vnsm7KuMc6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"WIsTycsgJf_b"},"outputs":[],"source":["!pip install torchmetrics\n","!pip install segmentation_models_pytorch\n","!pip install albumentations"]},{"cell_type":"code","source":["import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","import torchmetrics\n","from torchmetrics import Dice, JaccardIndex\n","import segmentation_models_pytorch as smp\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2 # np.array -> torch.tensor\n","import os\n","from tqdm import tqdm\n","from glob import glob\n","from torchvision.datasets import VOCSegmentation\n"],"metadata":{"id":"8tOyQHh9J3aV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cv2.setNumThreads(0)\n","cv2.ocl.setUseOpenCL(False)\n","\n","VOC_CLASSES = [\n","    \"background\",\n","    \"aeroplane\",\n","    \"bicycle\",\n","    \"bird\",\n","    \"boat\",\n","    \"bottle\",\n","    \"bus\",\n","    \"car\",\n","    \"cat\",\n","    \"chair\",\n","    \"cow\",\n","    \"diningtable\",\n","    \"dog\",\n","    \"horse\",\n","    \"motorbike\",\n","    \"person\",\n","    \"potted plant\",\n","    \"sheep\",\n","    \"sofa\",\n","    \"train\",\n","    \"tv/monitor\",\n","]\n","\n","VOC_COLORMAP = [\n","    [0, 0, 0],\n","    [128, 0, 0],\n","    [0, 128, 0],\n","    [128, 128, 0],\n","    [0, 0, 128],\n","    [128, 0, 128],\n","    [0, 128, 128],\n","    [128, 128, 128],\n","    [64, 0, 0],\n","    [192, 0, 0],\n","    [64, 128, 0],\n","    [192, 128, 0],\n","    [64, 0, 128],\n","    [192, 0, 128],\n","    [64, 128, 128],\n","    [192, 128, 128],\n","    [0, 64, 0],\n","    [128, 64, 0],\n","    [0, 192, 0],\n","    [128, 192, 0],\n","    [0, 64, 128],\n","]\n","\n","class PascalVOCSearchDataset(VOCSegmentation):\n","    def __init__(self, root=\"~/data/pascal_voc\", image_set=\"train\", download=True, transform=None):\n","        super().__init__(root=root, image_set=image_set, download=download, transform=transform)\n","\n","    @staticmethod\n","    def _convert_to_segmentation_mask(mask): # mask là 1 image RGB (H, W, 3)\n","        # This function converts a mask from the Pascal VOC format to the format required by AutoAlbument.\n","        #\n","        # Pascal VOC uses an RGB image to encode the segmentation mask for that image. RGB values of a pixel\n","        # encode the pixel's class.\n","        #\n","        # AutoAlbument requires a segmentation mask to be a NumPy array with the shape [height, width, num_classes].\n","        # Each channel in this mask should encode values for a single class. Pixel in a mask channel should have\n","        # a value of 1.0 if the pixel of the image belongs to this class and 0.0 otherwise.\n","        height, width = mask.shape[:2]\n","        segmentation_mask = np.zeros((height, width, len(VOC_COLORMAP)), dtype=np.float32) # tạo 1 object mask (H, W, 21)\n","        for label_index, label in enumerate(VOC_COLORMAP):\n","          segmentation_mask[:, :, label_index] = np.all(mask == label, axis=-1).astype(float) # mask == label trả về matrix T/F (H, W, 3) check từng pixel theo chiều sâu channels.\n","                                                                                              # np.all sẽ kiểm tra nếu pixel nào có channel cùng màu với VOC_COLORMAP thì trả về True, ta dc 1 matrix True/False (H, W).\n","                                                                                              # astype() convert matrix [True False] về kiểu float [1. 0.]\n","\n","        return segmentation_mask #0, 1, 2, 3, ..., 20 (H, W, C)\n","\n","    def __getitem__(self, index):\n","        image = cv2.imread(self.images[index])\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        mask = cv2.imread(self.masks[index])\n","        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n","        mask = self._convert_to_segmentation_mask(mask)\n","        if self.transform is not None:\n","          transformed = self.transform(image=image, mask=mask)\n","          image = transformed[\"image\"]\n","          mask = transformed[\"mask\"]\n","        return image, mask.argmax(dim=2).squeeze() #torch.tensor argmax()-> (H, W, 1) -> (H, W) #numpy"],"metadata":{"id":"GONR9cuvJ3X0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainsize = 256\n","\n","train_transform = A.Compose([\n","    A.Resize(width=trainsize, height=trainsize),\n","    A.HorizontalFlip(),\n","    A.RandomBrightnessContrast(),\n","    A.Blur(),\n","    A.Sharpen(),\n","    A.RGBShift(),\n","    A.Cutout(num_holes=5, max_h_size=25, max_w_size=25, fill_value=0),\n","    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0),\n","    ToTensorV2(),\n","])\n","\n","test_trainsform = A.Compose([\n","    A.Resize(width=trainsize, height=trainsize),\n","    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0),\n","    ToTensorV2(), # numpy.array -> torch.tensor (B, 3, H, W)\n","])"],"metadata":{"id":"qabG0sjEJ3Vc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class UnNormalize(object):\n","    def __init__(self, mean, std):\n","        self.mean = mean\n","        self.std = std\n","\n","    def __call__(self, tensor):\n","        \"\"\"\n","        Args:\n","            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n","        Returns:\n","            Tensor: Normalized image.\n","        \"\"\"\n","        for t, m, s in zip(tensor, self.mean, self.std):\n","            t.mul_(s).add_(m)\n","            # The normalize code -> t.sub_(m).div_(s)\n","        return tensor\n","\n","unorm = UnNormalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))"],"metadata":{"id":"bIpkYNHVJ3TL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = PascalVOCSearchDataset(image_set=\"train\", download=True, transform=train_transform)\n","test_dataset = PascalVOCSearchDataset(image_set=\"val\", download=True, transform=test_trainsform)\n","\n","image, mask = train_dataset.__getitem__(10)\n","plt.subplot(1, 2, 1)\n","plt.imshow(unorm(image).permute(1, 2, 0))\n","plt.subplot(1, 2, 2)\n","plt.imshow(mask)\n","plt.show()\n"],"metadata":{"id":"_TmgPhjEJ3RD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class AverageMeter(object):\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count"],"metadata":{"id":"Btuhur2fJ3Or"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def intersectionAndUnionGPU(output, target, K, ignore_index=255):\n","    # 'K' classes, output and target sizes are N or N * L or N * H * W, each value in range 0 to K - 1.\n","    assert (output.dim() in [1, 2, 3])\n","    assert output.shape == target.shape\n","    output = output.view(-1)\n","    target = target.view(-1)\n","    output[target == ignore_index] = ignore_index\n","    intersection = output[output == target]\n","    area_intersection = torch.histc(intersection, bins=K, min=0, max=K-1)\n","    area_output = torch.histc(output, bins=K, min=0, max=K-1)\n","    area_target = torch.histc(target, bins=K, min=0, max=K-1)\n","    area_union = area_output + area_target - area_intersection\n","    return area_intersection, area_union, area_target"],"metadata":{"id":"WDBdyfy6J3MY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","#load data\n","batch_size = 32\n","n_workers = os.cpu_count()\n","print(\"num_workers =\", n_workers)\n","trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n","                                          shuffle=True, num_workers=n_workers)\n","testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n","                                          shuffle=False, num_workers=n_workers)\n","\n","#model\n","model = smp.create_model(\"PAN\", \"timm-efficientnet-b4\", \"imagenet\", 3, 21).to(device)\n","\n","\n","#loss\n","criterion = smp.losses.DiceLoss(mode=\"multiclass\", classes=21)\n","\n","#optimizer\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.75)\n","n_eps = 25\n","\n","#meter\n","acc_meter = AverageMeter()\n","train_loss_meter = AverageMeter()\n","intersection_meter = AverageMeter()\n","union_meter = AverageMeter()\n","target_meter = AverageMeter()"],"metadata":{"id":"zSsIljsNJ3Dj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train\n","for ep in range(1, 1+n_eps):\n","  train_loss_meter.reset()\n","  intersection_meter.reset()\n","  union_meter.reset()\n","  target_meter.reset()\n","  model.train()\n","\n","  for batch_id, (x, y) in enumerate(tqdm(trainloader), start=1):\n","    optimizer.zero_grad()\n","    n = x.shape[0]\n","    x = x.to(device).float()\n","    y = y.to(device).long() # hàm entropy loss nhận output là indices của class trong class_list nên chuyển sang long = int64\n","    y_hat = model(x) #(B, C, H, W)\n","    loss = criterion(y_hat, y) #(B, C, H, W) >< (B, H, W)\n","    loss.backward()\n","    optimizer.step()\n","\n","    # save metrics\n","    with torch.no_grad():\n","      train_loss_meter.update(loss.item())\n","      y_hat_mask = y_hat.argmax(dim=1).squeeze(1) # (B, C, H, W) -> (B, 1, H, W) -> (B, H, W)\n","      intersection, union, target = intersectionAndUnionGPU(y_hat_mask.float(), y.float(), 21)\n","\n","      train_loss_meter.update(loss.item(), n)\n","      intersection_meter.update(intersection)\n","      union_meter.update(union)\n","      target_meter.update(target)\n","\n","  with torch.no_grad():\n","    iou_class = intersection_meter.sum / (union_meter.sum + 1e-10)  # vector 21D\n","    dice_class = (2 * intersection_meter.sum) / (intersection_meter.sum + union_meter.sum + 1e-10) #vector 21D\n","\n","    mIoU = torch.mean(iou_class)  #mean vector 21D\n","    mDice = torch.mean(dice_class)  #mean vector 21D\n","\n","  print(\"EP {}, current_lr = {}, train loss = {}, IoU = {}, Dice = {}\".format(ep, scheduler.get_last_lr(), train_loss_meter.avg, mIoU, mDice))\n","  scheduler.step()\n","\n","  print(\"EP {}, train loss = {}, IoU = {}, dice = {}\".format(\n","      ep, train_loss_meter.avg, mIoU, mDice\n","  ))\n","  if ep >= 20:\n","      torch.save(model.state_dict(), \"/content/modelPAN_ep_{}.pth\".format(ep))"],"metadata":{"id":"L9hdcE3BJ28l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# evaluation\n","model.eval()\n","test_intersection_meter = AverageMeter()\n","test_union_meter = AverageMeter()\n","test_target_meter = AverageMeter()\n","with torch.no_grad():\n","  for batch_id, (x, y) in enumerate(tqdm(testloader), start = 1):\n","    n = x.shape[0]\n","    x = x.to(device).float()\n","    y = y.to(device).long()\n","    y_hat = model(x)\n","    y_hat_mask = y_hat.argmax(dim = 1).squeeze()\n","\n","    intersection, union, target = intersectionAndUnionGPU(y_hat_mask.float(), y.float(), 21)\n","    intersection_meter.update(intersection)\n","    union_meter.update(union)\n","    target_meter.update(target)\n","\n","  iou_class = intersection_meter.sum / (union_meter.sum + 1e-10)  # vector 21D\n","  dice_class = (2 * intersection_meter.sum) / (intersection_meter.sum + union_meter.sum + 1e-10) #vector 21D\n","\n","  mIoU = torch.mean(iou_class)  #mean vector 21D\n","  mDice = torch.mean(dice_class)  #mean vector 21D\n","print(\"TEST: iou = {}, dice = {}\".format( mIoU, mDice))\n","\n"],"metadata":{"id":"CzPmC4NCVAfE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","# predict\n","id = random.randint(0, train_dataset.__len__())\n","\n","with torch.no_grad():\n","  model.eval()\n","  x, y = test_dataset.__getitem__(id)\n","  y_predict = model(x.unsqueeze(0).to(device)).argmax(dim=1).squeeze()\n","  intersection, union, target = intersectionAndUnionGPU(y_predict.float(), y.float(), 21)\n","  iou_class = intersection_meter.sum / (union_meter.sum + 1e-10)  # vector 21D\n","  dice_class = (2 * intersection_meter.sum) / (intersection_meter.sum + union_meter.sum + 1e-10) #vector 21D\n","\n","  mIoU = torch.mean(iou_class)  #mean vector 21D\n","  mDice = torch.mean(dice_class)  #mean vector 21D\n","  print(\"IoU = {}; Dice = {}\".format(mIoU, mDice))\n","  # print(np.unique(y_predict))\n","  # print(y_predict.shape)\n","  y_predict = y_predict.cpu().numpy()\n","  color_mask_predict = np.zeros((*y_predict.shape, 3))\n","  for i, color in enumerate(VOC_COLORMAP):\n","    color_mask_predict[y_predict==i] = np.array(color)\n","  color_mask = np.zeros((*y_predict.shape, 3))\n","  for i, color in enumerate(VOC_COLORMAP):\n","    color_mask[y==i] = np.array(color)\n","  plt.subplot(1,3,1)\n","  plt.imshow(unorm(x).permute(1, 2, 0))\n","  plt.subplot(1,3,2)\n","  plt.imshow(color_mask)\n","  plt.subplot(1,3,3)\n","  plt.imshow(color_mask_predict)\n","  plt.show()"],"metadata":{"id":"gvjyYtD2UzAY"},"execution_count":null,"outputs":[]}]}